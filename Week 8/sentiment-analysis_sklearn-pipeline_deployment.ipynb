{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edcfc715",
   "metadata": {},
   "source": [
    "# Deploying a Scikit-learn Pipeline for Online Inference with Vertex AI\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this notebook, we will walk through the complete, end-to-end process of deploying a machine learning model on Google Cloud for real-time predictions.\n",
    "\n",
    "Our goal is to take a logistic regression model, designed to predict the sentiment of customer reviews, and make it available as a live, scalable service using Vertex AI. This is a foundational workflow in modern Machine Learning Operations (MLOps).\n",
    "\n",
    "### Workflow Overview\n",
    "\n",
    "We will follow these key steps, simulating a professional MLOps lifecycle:\n",
    "\n",
    "1.  **Setup & Data Preparation:** Load the dataset, clean it, and split it for training and testing.\n",
    "2.  **Model Training with a Pipeline:** Build, train, and evaluate a scikit-learn `Pipeline` that combines our text vectorizer and classifier into a single, robust object.\n",
    "3.  **Saving the Model Artifact:** Save the validated pipeline to a single `model.joblib` file.\n",
    "4.  **Deploying to Vertex AI:**\n",
    "    * Upload the model artifact to Google Cloud Storage.\n",
    "    * Import the model into the Vertex AI Model Registry.\n",
    "    * Deploy the registered model to a live Vertex AI Endpoint.\n",
    "5.  **Getting Online Inferences:** Use the Vertex AI Python SDK to send a new review to our deployed endpoint and receive a real-time sentiment prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eef28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49731ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded the dataset.\n",
      "Dataset preview:\n",
      "                                         Review Text  sentiment\n",
      "0  Absolutely wonderful - silky and sexy and comf...          1\n",
      "1  Love this dress!  it's sooo pretty.  i happene...          1\n",
      "2  I love, love, love this jumpsuit. it's fun, fl...          1\n",
      "3  This shirt is very flattering to all due to th...          1\n",
      "4  I love tracy reese dresses, but this one is no...         -1\n"
     ]
    }
   ],
   "source": [
    "file_path = 'womens_clothing_ecommerce_reviews.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"✅ Successfully loaded the dataset.\")\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153dded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19818 entries, 0 to 19817\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Review Text  19818 non-null  object\n",
      " 1   sentiment    19818 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 309.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Get some basic information about the dataset\n",
    "print(\"\\nDataset Information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b937f97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data split into 15854 training samples and 3964 testing samples.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Split Data into Training and Testing Sets ---\n",
    "# It's crucial to test our model on data it has never seen before.\n",
    "# We'll use 80% of the data for training and 20% for testing.\n",
    "X = df['Review Text']\n",
    "y = df['sentiment']\n",
    "\n",
    "# 'stratify=y' ensures that the proportion of positive and negative reviews is the same in both your training set and your testing set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"\\nData split into {len(X_train)} training samples and {len(X_test)} testing samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d88091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the entire pipeline...\n",
      "✅ Pipeline training complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Define the pipeline ---\n",
    "# You put your fully configured vectorizer directly into the pipeline's steps.\n",
    "# All your settings, like 'stop_words' and 'max_features', go here.\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('classifier', LogisticRegression(max_iter=5000, solver='saga', random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# 2. TRAIN THE ENTIRE PIPELINE\n",
    "# You fit the pipeline on the raw text data. It handles the rest internally.\n",
    "# The pipeline will now use your configured vectorizer internally.\n",
    "print(\"Training the entire pipeline...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"✅ Pipeline training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7322b63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the pipeline on the test data...\n",
      "Model Accuracy on the test set: 0.9299\n"
     ]
    }
   ],
   "source": [
    "# --- 2. EVALUATE THE PIPELINE (The Quality Gate) ---\n",
    "# Use the trained pipeline to make predictions on the unseen test data.\n",
    "# The pipeline automatically handles the .transform() step for X_test.\n",
    "print(\"\\nEvaluating the pipeline on the test data...\")\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the performance. You can use any metric, like accuracy.\n",
    "score = accuracy_score(y_test, predictions)\n",
    "print(f\"Model Accuracy on the test set: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92e8e7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the pipeline to model.joblib...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. SAVE THE SINGLE, COMPLETE PIPELINE ARTIFACT\n",
    "# This object now contains your CountVectorizer\n",
    "# AND your trained LogisticRegression model.\n",
    "# This is the file you need to deploy. It knows how to handle raw text.\n",
    "print(\"Saving the pipeline to model.joblib...\")\n",
    "joblib.dump(pipeline, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a2aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0529d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. SET YOUR VARIABLES ---\n",
    "# Replace these with your actual project details from the Google Cloud console.\n",
    "PROJECT_ID = \"nice-test-470503\"\n",
    "LOCATION = \"asia-southeast1\"\n",
    "ENDPOINT_ID = \"1762528244441205760\" # The ID of your endpoint\n",
    "\n",
    "\n",
    "# --- 2. INITIALIZE THE CLIENT ---\n",
    "# This sets up the connection to your project.\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# --- 3. CREATE THE ENDPOINT OBJECT ---\n",
    "# This creates a local Python object that is a remote control for your live endpoint.\n",
    "endpoint = aiplatform.Endpoint(endpoint_name=ENDPOINT_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5032210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending new review to the model: 'I recently purchased this dress and I have to say, it exceeded my expectations. The fabric feels soft yet durable, and it has just the right amount of stretch to make it really comfortable for long wear. The stitching and finishing are neat, giving it a very polished look.'\n",
      "\n",
      "...Calling the endpoint...\n",
      "Prediction(predictions=[1], deployed_model_id='4742275014458343424', metadata=None, model_version_id='1', model_resource_name='projects/790592728786/locations/asia-southeast1/models/5690847884996509696', explanations=None)\n",
      "...Received a response.\n",
      "----------------------------------------\n",
      "✅ Prediction: The review sentiment is 'Positive'\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 2. THE NEW DATA ---\n",
    "# This is the new, raw text review we want to classify.\n",
    "# Note that it must be inside a list.\n",
    "new_review = [\"I recently purchased this dress and I have to say, it exceeded my expectations. The fabric feels soft yet durable, and it has just the right amount of stretch to make it really comfortable for long wear. The stitching and finishing are neat, giving it a very polished look.\"]\n",
    "print(f\"Sending new review to the model: '{new_review[0]}'\")\n",
    "\n",
    "\n",
    "# --- 5. MAKE THE PREDICTION CALL ---\n",
    "# The .predict() method sends the data to the live model.\n",
    "# The 'instances' argument must be a list.\n",
    "print(\"\\n...Calling the endpoint...\")\n",
    "response = endpoint.predict(instances=new_review)\n",
    "\n",
    "print(response)\n",
    "\n",
    "# --- 6. PARSE AND DISPLAY THE RESPONSE ---\n",
    "print(\"...Received a response.\")\n",
    "\n",
    "# The prediction result is stored in the .predictions attribute of the response.\n",
    "# Since we sent one review, we get one result at index [0].\n",
    "prediction_result = response.predictions[0]\n",
    "\n",
    "# Assuming your model was trained on labels where 1 is 'Positive' and 0 is 'Negative'.\n",
    "sentiment = \"Positive\" if prediction_result == 1 else \"Negative\"\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(f\"✅ Prediction: The review sentiment is '{sentiment}'\")\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ebe6902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sending prediction request to the Vertex AI endpoint...\n",
      "Prediction(predictions=[-1, -1, -1, 1, 1], deployed_model_id='4742275014458343424', metadata=None, model_version_id='1', model_resource_name='projects/790592728786/locations/asia-southeast1/models/5690847884996509696', explanations=None)\n",
      "<class 'google.cloud.aiplatform.models.Prediction'>\n",
      "[-1, -1, -1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "new_reviews = [\n",
    "    \"I am so disappointed with this purchase, I will be returning it.\",\n",
    "    \"The material felt cheap and it was not what I expected.\",\n",
    "    \"It's an okay product, not great but not terrible either.\",\n",
    "    \"This dress is absolutely beautiful and fits perfectly!\",\n",
    "    \"I recently purchased this dress and I have to say, it exceeded my expectations. The fabric feels soft yet durable, and it has just the right amount of stretch to make it really comfortable for long wear. The stitching and finishing are neat, giving it a very polished look.\"\n",
    "]\n",
    "\n",
    "print(\"\\nSending prediction request to the Vertex AI endpoint...\")\n",
    "# Make the prediction call\n",
    "response = endpoint.predict(instances=new_reviews)\n",
    "\n",
    "print(response)\n",
    "print(type(response))\n",
    "\n",
    "prediction_results = response.predictions\n",
    "print(prediction_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
