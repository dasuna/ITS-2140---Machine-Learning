{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1887a0d2",
   "metadata": {},
   "source": [
    "# ðŸš€ MLflow Tracking for the Sentiment Classifier with Logistic Regression\n",
    "\n",
    "This code demonstrates how to use MLflow for tracking and logging our well-known sentiment prediction model for the womenâ€™s clothing shop dataset, which we used throughout the classes over the past few weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d82f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b0b702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/23 20:10:45 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
      "2026/02/23 20:10:45 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
      "2026/02/23 20:10:45 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
      "2026/02/23 20:10:45 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
      "2026/02/23 20:10:45 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
      "2026/02/23 20:10:45 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
      "2026/02/23 20:10:45 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/23 20:10:45 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to: sqlite:///mlflow.db\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"Logistic-Regression-Experiment\")\n",
    "\n",
    "print(\"Connected to:\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94050fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the dataset.\n",
      "Dataset preview:\n",
      "                                         Review Text  sentiment\n",
      "0  Absolutely wonderful - silky and sexy and comf...          1\n",
      "1  Love this dress!  it's sooo pretty.  i happene...          1\n",
      "2  I love, love, love this jumpsuit. it's fun, fl...          1\n",
      "3  This shirt is very flattering to all due to th...          1\n",
      "4  I love tracy reese dresses, but this one is no...         -1\n"
     ]
    }
   ],
   "source": [
    "file_path = 'womens_clothing_ecommerce_reviews.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Successfully loaded the dataset.\")\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84c1e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data split into 15854 training samples and 3964 testing samples.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Split Data into Training and Testing Sets ---\n",
    "# It's crucial to test our model on data it has never seen before.\n",
    "# We'll use 80% of the data for training and 20% for testing.\n",
    "X = df['Review Text']\n",
    "y = df['sentiment']\n",
    "\n",
    "# 'stratify=y' ensures that the proportion of positive and negative reviews is the same in both your training set and your testing set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"\\nData split into {len(X_train)} training samples and {len(X_test)} testing samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff70d707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting text to numerical features using Bag-of-Words...\n",
      "X_train_bow Shape:\n",
      " (15854, 11897)\n",
      "Unique words (features): ['00' '000' '00p' ... 'zooming' 'zuma' 'Ã£Â¼ber']\n",
      "X_train_bow:\n",
      " <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 373991 stored elements and shape (15854, 11897)>\n",
      "  Coords\tValues\n",
      "  (0, 10214)\t1\n",
      "  (0, 2396)\t1\n",
      "  (0, 4805)\t1\n",
      "  (0, 4210)\t1\n",
      "  (0, 3835)\t1\n",
      "  (0, 9289)\t1\n",
      "  (0, 3680)\t1\n",
      "  (0, 4669)\t1\n",
      "  (0, 6980)\t1\n",
      "  (0, 10773)\t1\n",
      "  (0, 7248)\t1\n",
      "  (0, 7409)\t1\n",
      "  (1, 9289)\t1\n",
      "  (1, 2866)\t1\n",
      "  (1, 3454)\t1\n",
      "  (1, 4206)\t1\n",
      "  (1, 1781)\t1\n",
      "  (1, 6221)\t1\n",
      "  (1, 6711)\t1\n",
      "  (1, 8861)\t1\n",
      "  (1, 9671)\t1\n",
      "  (1, 9424)\t1\n",
      "  (1, 11)\t1\n",
      "  (2, 7409)\t1\n",
      "  (2, 3454)\t3\n",
      "  :\t:\n",
      "  (15853, 4805)\t1\n",
      "  (15853, 7596)\t1\n",
      "  (15853, 6257)\t1\n",
      "  (15853, 2390)\t1\n",
      "  (15853, 11495)\t1\n",
      "  (15853, 1602)\t1\n",
      "  (15853, 8053)\t1\n",
      "  (15853, 4742)\t1\n",
      "  (15853, 8467)\t1\n",
      "  (15853, 7829)\t1\n",
      "  (15853, 9466)\t1\n",
      "  (15853, 10594)\t1\n",
      "  (15853, 11408)\t1\n",
      "  (15853, 11414)\t1\n",
      "  (15853, 8195)\t1\n",
      "  (15853, 584)\t1\n",
      "  (15853, 11438)\t1\n",
      "  (15853, 5070)\t1\n",
      "  (15853, 11519)\t1\n",
      "  (15853, 9280)\t1\n",
      "  (15853, 9273)\t1\n",
      "  (15853, 5103)\t1\n",
      "  (15853, 3990)\t1\n",
      "  (15853, 521)\t1\n",
      "  (15853, 4857)\t1\n",
      "âœ… Text successfully converted to feature vectors.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Feature Engineering with Bag-of-Words ---\n",
    "# Here, we convert the text reviews into numerical feature vectors.\n",
    "# Each feature is a count of how many times a word appears in a review.\n",
    "print(\"\\nConverting text to numerical features using Bag-of-Words...\")\n",
    "\n",
    "# Initialize the vectorizer. `stop_words='english'` removes common\n",
    "# English words like 'the', 'a', 'is', which don't carry much sentiment.\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit the vectorizer on the TRAINING data and transform it into a matrix\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "print(f\"X_train_bow Shape:\\n {X_train_bow.shape}\")\n",
    "\n",
    "print(f\"Unique words (features): {vectorizer.get_feature_names_out()}\")\n",
    "\n",
    "# Output is a sparse matrix representation, where most entries are zero and only non-zero values are stored\n",
    "print(f\"X_train_bow:\\n {X_train_bow}\")\n",
    "\n",
    "# ONLY transform the TESTING data using the already-fitted vectorizer\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"âœ… Text successfully converted to feature vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22cadc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression model...\n",
      "Model training complete.\n",
      "\n",
      "Evaluating model on test set...\n",
      "Test Accuracy: 0.9299\n",
      "Test Precision: 0.8483\n",
      "Test Recall: 0.7988\n",
      "Test F1 Score: 0.8209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/mlflow/models/model.py:1209: FutureWarning: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization.The recommended safe alternative is the 'skops' format.\n",
      "  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic run logged. Accuracy: 0.9298688193743693 Precision: 0.8482978549505802 Recall: 0.7988212252003917 F1: 0.8208967837899686\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"logistic_regression_baseline\"):\n",
    "\n",
    "    \n",
    "    # --- Step 4: Train a Logistic Regression Model ---\n",
    "    print(\"\\nTraining Logistic Regression model...\")\n",
    "    model = LogisticRegression(max_iter=1000, solver='saga', random_state=42)  # max_iter increased to ensure convergence\n",
    "    model.fit(X_train_bow, y_train)\n",
    "    print(\"Model training complete.\")\n",
    "    \n",
    "    # --- Step 5: Evaluate the Model ---\n",
    "    print(\"\\nEvaluating model on test set...\")\n",
    "    y_pred = model.predict(X_test_bow)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Params (include requested fields)\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"solver\", \"saga\")\n",
    "    mlflow.log_param(\"max_iter\", 1000)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    \n",
    "    # Log the accuracy metric to MLflow\n",
    "    mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"test_precision\", precision)\n",
    "    mlflow.log_metric(\"test_recall\", recall)\n",
    "    mlflow.log_metric(\"test_f1\", f1)\n",
    "\n",
    "    mlflow.sklearn.log_model(model, name=\"logistic_model\")\n",
    "    print(\"Logistic run logged. Accuracy:\", accuracy, \"Precision:\", precision, \"Recall:\", recall, \"F1:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
